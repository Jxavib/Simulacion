---
title: "Reducción de la Varianza"
author: "Beltran Henry, Burbano Joel,Guaman Ronny"
date: "3/8/2021"
output: 
  html_document: 
    highlight: zenburn
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = F)
```

# Ejericio de Fin de Practica

***5. Aproximar  mediante integración Monte Carlo (clásica) el valor de la siguiente integral:$$I=\int_{-1}^1 \frac{1}{8}(5-3x^2)dx$$  y representar gráficamente la aproximación en función de $n$. Comparar los resultados con los obtenidos empleando variables antitéticas, ¿ Se produce una reducción de la varianza?***

Del taller anterior, sabemos que el valor exacto de la integración es 1. Ahora, exponemos primero la función que utilizaremos para calcular la aproximación de Monte Carlo (Clásica)

```{r}
#Haremos que esta función que nos devuelva los valores simulados, la aproximación a lo largo de n, y el error.
mc.integral <- function(f, a, b, n, plot=TRUE) {
  fx <- sapply(runif(n, a, b), f)*(b-a)
  #if (plot) {
    estint <- cumsum(fx)/(1:n)
    esterr <- sqrt(cumsum((fx-estint)^2))/(1:n)
   if (plot){ 
    plot(estint, ylab="Media y rango de error", type="l", lwd= 2, ylim=mean(fx)+2*c(-esterr[1],esterr[1]), xlab="Iteraciones")
    abline(h=estint[n],lty=2)
    lines(estint+2*esterr, col="gold", lwd=3)
    lines(estint-2*esterr, col="gold", lwd=3)
    return(list(x=fx,estint=estint,esterr=esterr,valor=estint[n], error=2*esterr[n])) 
  } else return(list(x=fx,estint=estint,esterr=esterr,valor=mean(fx), error=2*sd(fx)/sqrt(n))) 
}  
```

Ahora, expondremos la función a utilizar para aproximar por el método de Monte Carlo con variables antitéticas( asumiendo independencia):


```{r}
mc.integral_anti <- function(ftn, a, b, n, plot=TRUE) {
 x <- runif(n%/%2, a, b)
 x <- as.numeric(matrix(c(x,a+b-x),nrow=2,byrow=TRUE)) # genera los valores de x y su antitetica en orden x1,ant1,x2,ant2
 fx <- sapply(x, ftn)*(b-a)
 #if (plot) {
    estint <- cumsum(fx)/(1:n)
    esterr <- sqrt(cumsum((fx-estint)^2))/(1:n)
  if(plot) {
    plot(estint, ylab="Media y rango de error", type="l", lwd= 2, ylim=mean(fx)+2*c(-esterr[1],esterr[1]), xlab="Iteraciones")
    abline(h=estint[n],lty=2)
    lines(estint+2*esterr,col="gold",lwd=2)
    lines(estint-2*esterr,col="gold",lwd=2)
    return(list(x=fx,estint=estint,esterr=esterr,valor=estint[n],error=2*esterr[n]))
  } else return(list(x=fx,estint=estint,esterr=esterr,valor=mean(fx),error=2*sd(fx)/sqrt(n))) 
}
```

Ahora, expondremos la función a utilizar para aproximar por el método de Monte Carlo con variables antitéticas( asumiendo dependencia):

```{r}
# monte carlo antitetica asumiendo dependencia
mc.integral_anti_dep <- function(ftn, a, b, n, plot=TRUE) {
 x <- runif(n%/%2, a, b)
 x <- matrix(c(x,a+b-x),nrow=2,byrow=TRUE) 
 fx <- apply(x,1,ftn)*(b-a)
 corr <- cor(fx[,1],fx[,2])
 fx <- as.numeric(fx)
 #if (plot) {
    estint <- cumsum(fx)/(1:n)
    esterr <- sqrt(cumsum((fx-estint)^2))/(1:n)
  if(plot) {
    plot(estint, ylab="Media y rango de error", type="l", lwd= 2, ylim=mean(fx)+2*c(-esterr[1],esterr[1]), xlab="Iteraciones")
    abline(h=estint[n],lty=2)
    lines(estint+2*esterr,col="gold",lwd=2)
    lines(estint-2*esterr,col="gold",lwd=2)
    return(list(x=fx,estint=estint,esterr=esterr,valor=estint[n],error=2*esterr[n]))
  } else return(list(x=fx,estint=estint,esterr=esterr,valor=mean(fx),error=2*sd(fx)/sqrt(n)*sqrt(1+corr))) 
}
```



Para la aproximación por Monte Carlo (clásico) y con variables antitéticas, utilizaremos el método de inversión, por lo que nuestra nueva función objetivo, a partir de la distribución exponencial, será la siguiente:

```{r}
finv<-function(x) ifelse((x<=5/8),sqrt((5-8*x)/3), 0)
f <- function(x) return((1/8)*(5-3*x^2))
```

Por lo tanto, los nuevos límites entre los que se evaluará a la función serán 

Ahora bien, para realizar la comparación entre Monte Carlo y Monte Carlo con variables antitéticas, vamos a usar valores de n=100,500,1000
y observaremos sus resultados.

Para n=100


```{r}
n=100

set.seed(1750)
#Simulamos para Monte Carlo clásico para la funcion original
x_mc <- mc.integral(finv, 0,sqrt(5/3) ,n,plot = T)
fx_mc <- x_mc[[1]]
acum_mc <- x_mc[[2]]
esterr_mc <- x_mc[[3]]
error_mc <- x_mc$error

```

```{r}
#Simulamos para Monte Carlo antitetica
set.seed(1750)
x_mca <- mc.integral_anti(finv,0,sqrt(13/3), n,plot=T)
fx_mca <- x_mca[[1]]
acum_mca <- x_mca[[2]]
error_mca <- x_mca$error
```

```{r}
#Simulacion monte carlo antitetica asumiendo dependencia
set.seed(1750)
x_mcad <- mc.integral_anti_dep(finv, 0,sqrt(5/3) ,n,plot = T)
fx_mcad <- x_mcad[[1]]
acum_mcad <- x_mcad[[2]]
esterr_mcad <- x_mcad[[3]]
error_mcad <- x_mcad$error
```


Comparación de resultados
```{r echo=FALSE}
Aproximación <- c(mean(fx_mc),mean(fx_mca),mean(fx_mcad))
Error <- c(error_mc,error_mca,error_mcad)
p <- cbind(Aproximación,Error)
row.names(p) <- c('Monte Carlo Clásico','Monte Carlo Antitética','Monte Carlo Antitética(Dependencia)')
#Construcción de tabla de resultados con formato
library(knitr)
kable(p,align = 'l', digits = round(4))
```



Gráfica:


```{r}
plot(acum_mc, ylab="Media y rango de error", type="l", lwd= 2, ylim=mean(fx_mc)+2*c(-esterr_mc[1],esterr_mc[1]), xlab="Iteraciones") 
abline(h = 2, lty = 2)
lines(acum_mca,col='cadetblue')
lines(acum_mcad,col='blue')
legend(x = "topright", legend = c("M-C clásico", "M-C antitético","M-C antitetico(dep)"), fill = c("black", "cadetblue","blue") )
```

Analizando ahora, el error cometido y la varianza tenemos:

Asumiendo independencia:

_Porcentaje estimado de reducción del error:_

```{r}
100*( (x_mc$error - x_mca$error)/ x_mc$error )
```
_Porcentaje de Reducción de la varianza_
```{r}
100*((var(fx_mc) - var(fx_mca))/var(fx_mc))
```
Asumiendo dependencia:

_Porcentaje estimado de reducción del error:_

```{r}
100*( (x_mc$error - x_mcad$error)/ x_mc$error )
```
_Porcentaje de Reducción de la varianza_
```{r}
100*((var(fx_mc) - var(fx_mcad))/var(fx_mc))
```

_Para $n=500$_

```{r}
n=500
#Simulamos para Monte Carlo clásico
set.seed(1750)
x_mc <- mc.integral(finv, 0, sqrt(5/3),n,plot = FALSE)
fx_mc <- x_mc[[1]]
acum_mc <- x_mc[[2]]
esterr_mc <- x_mc[[3]]
error_mc <- x_mc$error

#Simulamos para Monte Carlo con antitéticas
set.seed(1750)
x_mca <- mc.integral_anti(finv, 0, sqrt(5/3), n,plot = FALSE)
fx_mca <- x_mca[[1]]
acum_mca <- x_mca[[2]]
error_mca <- x_mca$error

#Simulacion monte carlo antitetica asumiendo dependencia
set.seed(1750)
x_mcad <- mc.integral_anti_dep(finv, 0,sqrt(5/3) ,n,plot = F)
fx_mcad <- x_mcad[[1]]
acum_mcad <- x_mcad[[2]]
esterr_mcad <- x_mcad[[3]]
error_mcad <- x_mcad$error
```

Comparación de resultados
```{r echo=FALSE}
Aproximación <- c(mean(fx_mc),mean(fx_mca),mean(fx_mcad))
Error <- c(error_mc,error_mca,error_mcad)
p <- cbind(Aproximación,Error)
row.names(p) <- c('Monte Carlo Clásico','Monte Carlo Antitética','Monte Carlo Antitética(dep)')

kable(p,align = 'l', digits = round(4))
```

Gráfica:



```{r}
plot(acum_mc, ylab="Media y rango de error", type="l", lwd= 2, ylim=mean(fx_mc)+2*c(-esterr_mc[1],esterr_mc[1]), xlab="Iteraciones")
abline(h = 2, lty = 2)
lines(acum_mca,col='cadetblue')
lines(acum_mcad,col='blue')
legend(x = "topright", legend = c("M-C clásico", "M-C antitético"), fill = c("black", "cadetblue","blue") )
```

Analizando ahora, el error cometido y la varianza tenemos:

Asumiendo independencia:
_Porcentaje estimado de reducción del error:_

```{r}
100*( (x_mc$error - x_mca$error)/ x_mc$error )
```
_Porcentaje de Reducción de la varianza_

```{r}
100*((var(fx_mc) - var(fx_mca))/var(fx_mc))
```

Asumiendo dependencia:

_Porcentaje estimado de reducción del error:_

```{r}
100*( (x_mc$error - x_mcad$error)/ x_mc$error )
```
_Porcentaje de Reducción de la varianza_
```{r}
100*((var(fx_mc) - var(fx_mcad))/var(fx_mc))
```


_Para $n=1000$_
```{r}
n=1000

#Simulamos para Monte Carlo clásico
set.seed(1750)
x_mc <- mc.integral(finv, 0, 1,n,plot = FALSE)
fx_mc <- x_mc[[1]]
acum_mc <- x_mc[[2]]
esterr_mc <- x_mc[[3]]
error_mc <- x_mc$error

#Simulamos para Monte Carlo con antitéticas
set.seed(1750)
x_mca <- mc.integral_anti(finv, 0, 1, n,plot = FALSE)
fx_mca <- x_mca[[1]]
acum_mca <- x_mca[[2]]
error_mca <- x_mca$error

#Simulacion monte carlo antitetica asumiendo dependencia
set.seed(1750)
x_mcad <- mc.integral_anti_dep(finv, 0,sqrt(5/3) ,n,plot = F)
fx_mcad <- x_mcad[[1]]
acum_mcad <- x_mcad[[2]]
esterr_mcad <- x_mcad[[3]]
error_mcad <- x_mcad$error

```

Comparación de resultados
```{r echo=FALSE}
Aproximación <- c(mean(fx_mc),mean(fx_mca),mean(fx_mcad))
Error <- c(error_mc,error_mca,error_mcad)
p <- cbind(Aproximación,Error)
row.names(p) <- c('Monte Carlo Clásico','Monte Carlo Antitética','Monte Carlo Antitética(dep) ')

kable(p,align = 'l', digits = round(4))
```

Gráfica:


```{r}
plot(acum_mc, ylab="Media y rango de error", type="l", lwd= 2, ylim=mean(fx_mc)+2*c(-esterr_mc[1],esterr_mc[1]), xlab="Iteraciones")
abline(h = 2, lty = 2)
lines(acum_mca,col='cadetblue')
lines(acum_mcad,col='blue')
legend(x = "topright", legend = c("M-C clásico", "M-C antitético","M-C antitético(dep)"), fill = c("black", "cadetblue","blue") )
```

Analizando ahora, el error cometido y la varianza tenemos:

Asumiendo independecia:

_Porcentaje estimado de reducción del error:_

```{r}
100*( (x_mc$error - x_mca$error)/ x_mc$error )
```
_Porcentaje de Reducción de la varianza_
```{r}
100*((var(fx_mc) - var(fx_mca))/var(fx_mc))
```

Asumiendo dependencia:

_Porcentaje estimado de reducción del error:_

```{r}
100*( (x_mc$error - x_mcad$error)/ x_mc$error )
```
_Porcentaje de Reducción de la varianza_
```{r}
100*((var(fx_mc) - var(fx_mcad))/var(fx_mc))
```


***Aproximar mediante integración Monte Carlo (clásica) la media de una distribución exponencial
de parámetro $1/2$: $$I=\int_0^\infty \frac{x}{2}e^{-\frac{x}{2}} dx$$ y representar gráficamente la aproximación en función de $n$. Comparar los resultados con los obtenidos empleando variables antitéticas, ¿se produce una reducción en la varianza?***

<span style="color: DarkRed;">NOTA:</span> Puede ser recomendable emplear el método de inversión para generar las muestras (antitéticas) de la exponencial.


```{r eval=FALSE, include=FALSE}
# Desarrollo e implementación en r 

# MC Clásico
nsim <- 1000
lambda <- 0.5
set.seed(1)
u <- runif(nsim%/%2)
x <- - log(u) / lambda

mean(x) # Aprox por MC  # valor teor 1/lambda = 2
vx<-var(x)  # medida precisión
vx

xa <- - log(1-u) / lambda
mean(xa) # Aprox por MC  # valor teor 1/lambda = 2
vxa<-var(xa)  # medida precisión
# NOTA: Varianza suponiendo independencia
vxa

corr <- cor(x,xa)
xt <- c(x,xa)
mean(xt) # Aprox por MC  # valor teor 1/lambda = 2
vxt <- var(xa)*(1 + corr) # Estimación varianza suponiendo dependencia

# Estimación del porcentaje de reducción en la varianza
100*(var(x)-vxt )/var(x)

```

```{r}
#ejercicio 5

# -------------------------------
mc.integral <- function(ftn, n, plot=TRUE) {
  # Integración Monte Carlo
  # -------------------------------
  fx <- sapply(runif(n%/%2), ftn)
  m <- n%/%2
  if (plot) {
    estint <- cumsum(fx)/(1:m)
    esterr <- sqrt(cumsum((fx-estint)^2))/(1:m)
    estvar <- sum((fx-estint)^2)/(1:m)
    plot(estint, ylab="Media y rango de error", type="l", lwd= 2, ylim=mean(fx)+2*c(-esterr[1],esterr[1]), xlab="Iteraciones")
    lines(estint+2*esterr, col="gold", lwd=2)
    lines(estint-2*esterr, col="gold", lwd=2)
    return(list(x=fx,valor=estint[m], error=2*esterr[m],vx=estvar[m]))  
  } else return(list(x=fx,valor=mean(fx), error=2*sd(fx)/sqrt(m),vx=var(fx)))
}  
lambda <- 0.5
ftn <- function(x) return(-log(x)/lambda)
nsim <- 10^3
set.seed(1)
x <- mc.integral(ftn, nsim,plot = T)

fantit <- function(x) return(-log(1-x)/lambda)
set.seed(1)
xa <- mc.integral(fantit,nsim,plot=T)

#correlacion
corr <- cor(x$x,xa$x)
xt <- c(x$x,xa$x)
mean(xt)

vxt <- var(xa$x)*(1+corr) #estimación varianza suponiendo dependencia

#Estimación del porcentaje de reducción en la varianza
100*(var(x$x)-vxt )/var(x$x)

```

